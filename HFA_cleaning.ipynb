{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sql_functions_sp as sf\n",
    "import python_functions_sp as pf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floats (decimal numbers) should be displayed rounded with 2 decimal places\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "# Set style for plots\n",
    "plt.style.use('fivethirtyeight') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import tables as DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'capstone_health_education'\n",
    "table = 'HFA_data_p1_filtered'\n",
    "\n",
    "sql_query = f'SELECT * FROM {schema}.\"{table}\";'\n",
    "HFA_data_p1 = sf.get_dataframe(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'capstone_health_education'\n",
    "table = 'HFA_data_p2_filtered'\n",
    "\n",
    "sql_query = f'SELECT * FROM {schema}.\"{table}\";'\n",
    "HFA_data_p2 = sf.get_dataframe(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'capstone_health_education'\n",
    "table = 'HFA_data_p3_filtered'\n",
    "\n",
    "sql_query = f'SELECT * FROM {schema}.\"{table}\";'\n",
    "HFA_data_p3 = sf.get_dataframe(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put column names in lower case and snake case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_data_p1 = pf.columns_lower_snake_case_2(HFA_data_p1)\n",
    "HFA_data_p2 = pf.columns_lower_snake_case_2(HFA_data_p2)\n",
    "HFA_data_p3 = pf.columns_lower_snake_case_2(HFA_data_p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_data_p1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_data_p2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_data_p3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the three DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [HFA_data_p1, HFA_data_p2, HFA_data_p3]\n",
    "HFA_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df.shape    # 569+88++442 = 1900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - EDA\n",
    "- understand the data\n",
    "- drop unneeded columns\n",
    "- duplicates\n",
    "- missing values\n",
    "- descriptive statistics\n",
    "- extreme values / outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the Data\n",
    "remember: dtype 'object' means string or mixed data-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df['country_region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore and Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Unneeded columns** are dropped yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for **duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for **missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2020, 2021 and 2022 we have data for less than 50% of the countries / regions OR measure variables => drop these years?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df.groupby(['measure_code']).count().iloc[:, :12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df.groupby(['measure_code']).count().iloc[:, 12:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less data for:\n",
    "- HFA_411\n",
    "- some years in HFA_417, especially since 2016\n",
    "- **HFA_625**: only data for two years => drop it!\n",
    "- a lot of missing values for years **2020**, **2021**, **2022** => drop them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping HFA_625: \"Number cigarettes consumed per person per year\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df['measure_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df = HFA_df[~(HFA_df['measure_code'] == 'HFA_625')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df['measure_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename values, i.e. give values meaningful names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join various tables to...\n",
    "- rename the measure variables\n",
    "- give full name to countries and regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the measure variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'capstone_health_education'\n",
    "table = 'HFA_metadata_sh4'\n",
    "\n",
    "# sql_query = f'SELECT * FROM {schema}.\"{table}\";'\n",
    "sql_query = f'SELECT \"Measure labels\", \"Unnamed: 1\" FROM {schema}.\"{table}\" WHERE \"Measure labels\" LIKE \\'HFA%%\\';'\n",
    "measure_names = sf.get_dataframe(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema = 'capstone_health_education'\n",
    "# table = 'HFA_metadata_sh4'\n",
    "\n",
    "# # sql_query = f'SELECT * FROM {schema}.\"{table}\";'\n",
    "# sql_query = f'SELECT \"Measure labels\", \"Unnamed: 1\" FROM {schema}.\"{table}\";'\n",
    "# measure_names = sf.get_dataframe(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_names.rename(columns={'Measure labels': 'measure_code', 'Unnamed: 1': 'measure_label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df = pd.merge(HFA_df, measure_names, on='measure_code', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give full names to countries and regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'capstone_health_education'\n",
    "table = 'HFA_metadata_sh5'\n",
    "\n",
    "sql_query = f'SELECT * FROM {schema}.\"{table}\";'\n",
    "country_names = sf.get_dataframe(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_names.drop(['ISO 2', 'ISO 3', 'WHO code', 'Short name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_names.rename(columns={'Code': 'country_region', 'Full name': 'name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'capstone_health_education'\n",
    "table = 'HFA_metadata_sh6'\n",
    "\n",
    "sql_query = f'SELECT * FROM {schema}.\"{table}\";'\n",
    "region_names = sf.get_dataframe(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_names.drop(['Full name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_names.rename(columns={'Code': 'country_region', 'Short name': 'name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = pd.concat([country_names, region_names], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df = pd.merge(HFA_df, cat, on='country_region', how='left').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df = HFA_df[['measure_code', 'measure_label', 'country_region', 'name', '2000', '2001', '2002', '2003',\n",
    "       '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012',\n",
    "       '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021',\n",
    "       '2022']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df #.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some **descriptive statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df.iloc[:, :15].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df.iloc[:, 15:].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short explanation of the reported measures:\n",
    "- count: Indication of how many values are present in the columns (NaNs/missing values are not counted).\n",
    "- mean: average value of the data\n",
    "- std: standard deviation of the data\n",
    "- min: the smallest value in the data set\n",
    "- 25%: 25 % of the data are below this value\n",
    "- 50%: 50% of the data are below this value. This value is called the median.\n",
    "- 75%: 75% of the data are below this value\n",
    "- max: the largest expression in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for **extreme values / outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with the numbers in the year-columns **split the huge DataFrame** for each measure code into smaller ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df['measure_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_codes = ['HFA_1', 'HFA_43', 'HFA_10', 'HFA_167', 'HFA_13', 'HFA_16',\n",
    "               'HFA_19', 'HFA_101', 'HFA_194', 'HFA_260', 'HFA_417', 'HFA_275',\n",
    "               'HFA_293', 'HFA_357', 'HFA_411', 'HFA_436', 'HFA_440', 'HFA_441',\n",
    "               'HFA_442', 'HFA_443', 'HFA_444', 'HFA_445', 'HFA_446', 'HFA_454',\n",
    "               'HFA_546', 'HFA_566', 'HFA_617', 'HFA_618', 'HFA_627', 'HFA_636',\n",
    "               'HFA_637']\n",
    "\n",
    "# Create new list to safe the new DataFrames\n",
    "new_dataframes = []\n",
    "\n",
    "# Iterate over the measure codes\n",
    "for code in measure_codes:\n",
    "    # Filter the row for each year\n",
    "    HFA_df_measure_code = HFA_df[HFA_df['measure_code'] == code].copy()\n",
    "\n",
    "    # Add the new DataFrame to the list\n",
    "    new_dataframes.extend([HFA_df_measure_code])\n",
    "\n",
    "# Save the newly created DataFrames in new Variables\n",
    "(HFA_1, HFA_43, HFA_10, HFA_167, HFA_13, HFA_16,\n",
    "HFA_19, HFA_101, HFA_194, HFA_260, HFA_417, HFA_275,\n",
    "HFA_293, HFA_357, HFA_411, HFA_436, HFA_440, HFA_441,\n",
    "HFA_442, HFA_443, HFA_444, HFA_445, HFA_446, HFA_454,\n",
    "HFA_546, HFA_566, HFA_617, HFA_618, HFA_627, HFA_636,\n",
    "HFA_637) = new_dataframes[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [HFA_1, HFA_43, HFA_10, HFA_167, HFA_13, HFA_16,\n",
    "            HFA_19, HFA_101, HFA_194, HFA_260, HFA_417, HFA_275,\n",
    "            HFA_293, HFA_357, HFA_411, HFA_436, HFA_440, HFA_441,\n",
    "            HFA_442, HFA_443, HFA_444, HFA_445, HFA_446, HFA_454,\n",
    "            HFA_546, HFA_566, HFA_617, HFA_618, HFA_627, HFA_636,\n",
    "            HFA_637]\n",
    "\n",
    "for df in dataframes:\n",
    "    df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that only one code is saved in each DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(HFA_1['measure_code'].unique(), \n",
    "      HFA_43['measure_code'].unique(), \n",
    "      HFA_10['measure_code'].unique(), \n",
    "      HFA_167['measure_code'].unique(), \n",
    "      HFA_13['measure_code'].unique(), \n",
    "      HFA_16['measure_code'].unique(), \n",
    "      HFA_19['measure_code'].unique(), \n",
    "      HFA_101['measure_code'].unique(), \n",
    "      HFA_194['measure_code'].unique(), \n",
    "      HFA_260['measure_code'].unique(), \n",
    "      HFA_417['measure_code'].unique(), \n",
    "      HFA_275['measure_code'].unique(), \n",
    "      HFA_293['measure_code'].unique(), \n",
    "      HFA_357['measure_code'].unique(), \n",
    "      HFA_411['measure_code'].unique(), \n",
    "      HFA_436['measure_code'].unique(), \n",
    "      HFA_440['measure_code'].unique(), \n",
    "      HFA_441['measure_code'].unique(), \n",
    "      HFA_442['measure_code'].unique(), \n",
    "      HFA_443['measure_code'].unique(), \n",
    "      HFA_444['measure_code'].unique(), \n",
    "      HFA_445['measure_code'].unique(), \n",
    "      HFA_446['measure_code'].unique(), \n",
    "      HFA_454['measure_code'].unique(), \n",
    "      HFA_546['measure_code'].unique(), \n",
    "      HFA_566['measure_code'].unique(), \n",
    "      HFA_617['measure_code'].unique(), \n",
    "      HFA_618['measure_code'].unique(), \n",
    "      HFA_627['measure_code'].unique(), \n",
    "      HFA_636['measure_code'].unique(), \n",
    "      HFA_637['measure_code'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "# Liste der measure labels\n",
    "measure_labels = ['Mid-year population, by sex',\n",
    "       'Life expectancy at birth (years), by sex',\n",
    "       '% of population aged 0–14 years, by sex',\n",
    "       'Motor vehicle traffic accidents, all ages, per 100 000, by sex (age-standardized death rate)',\n",
    "       '% of population aged 65+ years, by sex',\n",
    "       'Live births per 1000 population, by sex',\n",
    "       'Number of live births, by sex',\n",
    "       'Diseases of circulatory system, all ages, per 100 000, by sex (age-standardized death rate)',\n",
    "       'All causes, all ages, per 100 000, by sex (age-standardized death rate)',\n",
    "       'Mental disorders, diseases of nervous system and sense organs, all ages, per 100 000, by sex (age-standardized death rate)',\n",
    "       '% population self-assessing health as good, by sex',\n",
    "       'Symptoms, signs and ill-defined conditions, all ages, per 100 000, by sex (age-standardized death rate)',\n",
    "       'Selected alcohol-related causes, per 100 000, by sex (age-standardized death rate)',\n",
    "       'Incidence of cancer per 100 000, by sex',\n",
    "       'Absenteeism from work due to illness, days per employee per year',\n",
    "       'Road traffic accidents with injury per 100 000',\n",
    "       'Average number of calories available per person per day (kcal)',\n",
    "       '% of total energy available from fat',\n",
    "       'Fat available per person per day (g)',\n",
    "       '% of total energy available from protein',\n",
    "       'Protein available per person per day (g)',\n",
    "       'Average amount of cereal available per person per year (kg)',\n",
    "       'Average amount of fruits and vegetables available per person per year (kg)',\n",
    "       'People injured due to work-related accidents per 100 000',\n",
    "       'Surgical wound infection rate (%), all operations',\n",
    "       'Total health expenditure as % of GDP',\n",
    "       'GINI coefficient (income distribution)',\n",
    "       'Proportion of children of official primary school age not enrolled, by sex',\n",
    "       'Age-standardized prevalence of overweight (defined as BMI = 25 kg/m2) in people aged 18 years and over, WHO estimates (%), by sex',\n",
    "       'Healthy life expectancy (HALE) at birth',\n",
    "       'Youth unemployment rate, % of total labor force ages 15-25']\n",
    "\n",
    "# Liste der DataFrame-Namen\n",
    "dataframe_keys = ['HFA_1', 'HFA_43', 'HFA_10', 'HFA_167', 'HFA_13', 'HFA_16', 'HFA_19', 'HFA_101', 'HFA_194', 'HFA_260', \n",
    "                  'HFA_417', 'HFA_275', 'HFA_293', 'HFA_357', 'HFA_411', 'HFA_436', 'HFA_440', 'HFA_441', 'HFA_442', \n",
    "                  'HFA_443', 'HFA_444', 'HFA_445', 'HFA_446', 'HFA_454', 'HFA_546', 'HFA_566', 'HFA_617', 'HFA_618', \n",
    "                  'HFA_627', 'HFA_636', 'HFA_637']\n",
    "\n",
    "# Sicherstellen, dass die Anzahl der measure labels mit der Anzahl der DataFrame-Namen übereinstimmt\n",
    "assert len(measure_labels) == len(dataframe_keys), \"Die Anzahl der measure labels muss mit der Anzahl der DataFrame-Namen übereinstimmen.\"\n",
    "\n",
    "# Calculate the number of rows and columns for the subplots\n",
    "n_cols = 3\n",
    "n_rows = (len(dataframe_keys) + n_cols - 1) // n_cols\n",
    "\n",
    "# Generate boxplots for each dataframe\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 5))\n",
    "\n",
    "# Flatten axes array for easy iteration if it's multi-dimensional\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Set the max width for wrapping titles\n",
    "max_title_width = 30\n",
    "\n",
    "for i, (label, key) in enumerate(zip(measure_labels, dataframe_keys)):\n",
    "    df = globals()[key]  # Zugriff auf die DataFrames über ihren Namen\n",
    "    df.boxplot(ax=axes[i])\n",
    "    wrapped_title = \"\\n\".join(textwrap.wrap(label, max_title_width))\n",
    "    axes[i].set_title(wrapped_title)\n",
    "    plt.setp(axes[i].xaxis.get_majorticklabels(), rotation=90, fontsize=10)\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the DataFrames to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes = [HFA_1, HFA_43, HFA_10, HFA_167, HFA_13, HFA_16,\n",
    "#               HFA_19, HFA_101, HFA_194, HFA_260, HFA_417, HFA_275,\n",
    "#               HFA_293, HFA_357, HFA_411, HFA_436, HFA_440, HFA_441,\n",
    "#               HFA_442, HFA_443, HFA_444, HFA_445, HFA_446, HFA_454,\n",
    "#               HFA_546, HFA_566, HFA_617, HFA_618, HFA_627, HFA_636,\n",
    "#               HFA_637]\n",
    "\n",
    "# table_names = ['hfa_1', 'hfa_43', 'hfa_10', 'hfa_167', 'hfa_13', 'hfa_16',\n",
    "#                'hfa_19', 'hfa_101', 'hfa_194', 'hfa_260', 'hfa_417', 'hfa_275',\n",
    "#                'hfa_293', 'hfa_357', 'hfa_411', 'hfa_436', 'hfa_440', 'hfa_441',\n",
    "#                'hfa_442', 'hfa_443', 'hfa_444', 'hfa_445', 'hfa_446', 'hfa_454',\n",
    "#                'hfa_546', 'hfa_566', 'hfa_617', 'hfa_618', 'hfa_627', 'hfa_636',\n",
    "#                'hfa_637']\n",
    "\n",
    "# for df, table_name in zip(dataframes, table_names):\n",
    "#     sf.push_to_cloud(df, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf.push_to_cloud(HFA_df, 'hfa_filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing a flip-flop to turn the year-columns into rows and the measure codes into columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning the year-columns into rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_melted = pd.melt(HFA_df,\n",
    "                      id_vars=['country_region', 'name', 'measure_code', 'measure_label'],\n",
    "                      value_vars=['2000','2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022'],\n",
    "                      var_name='years',\n",
    "                      value_name='value'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_melted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_melted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_melted_pivoted = pd.pivot(HFA_melted,\n",
    "                       columns='measure_code',\n",
    "                       index=['name', 'years'],\n",
    "                       values='value'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_melted_pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_melted_pivoted.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_melted_pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_melted_pivoted.columns.name=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_melted_pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_melted_pivoted.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write this melted and pivoted DataFrame into the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf.push_to_cloud(HFA_melted_pivoted, 'hfa_melted_pivoted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the whole string of the columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "pd.DataFrame({'measure_code': HFA_df['measure_code'].unique(),\n",
    "                    'measure_label': HFA_df['measure_label'].unique()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFA_df['name'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
